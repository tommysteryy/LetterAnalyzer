{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Math Textbooks vs The World\n",
    "\n",
    "### An NLP Investigation about Language Usage in Math Textbooks by Tommy Xu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the Data\n",
    "\n",
    "First, I had to use multiple packages for this particular project:\n",
    "- pandas was useful for setting up dataframes and plotting\n",
    "- requests and bs4 allowed me webscraping tools to pull text off of any website\n",
    "- re was used to ensure standard formatting for all my text\n",
    "- collections.Counter was the primary letter counter in my work\n",
    "- matplotlib.pyplot and wordcloud.WordCloud were primarily used for data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import bs4\n",
    "import string\n",
    "import re\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using these tools, I developed functions that could read all the words and letters from a website using only the URL. This was possible thanks to the powerful tools of BeautifulSoup and RegEx syntax. For words(), it produces a list of all words used in the page, and letters() produces a long string that contains all letters from the webpage. These were designed to be this way since collections.Counter can transform this information into a dictionary of frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words(url):\n",
    "    '''\n",
    "    Consumes a url of a webpage, produces a list of all the words used in the page\n",
    "    '''\n",
    "    req = requests.get(url)\n",
    "    soup = bs4.BeautifulSoup(req.text, 'lxml')\n",
    "    \n",
    "    lowords = filter(lambda x: x != \" \", soup.get_text().lower().replace('\\n', ' ')         # Pre-formatting the text and \n",
    "                     .translate(str.maketrans(\"\", \"\", string.punctuation)).split(\" \"))      # splitting by \" \"\n",
    "    \n",
    "    lowords_lst = []\n",
    "    for word in lowords:\n",
    "        if word.isdigit():                          ## For this analysis, digits were excluded\n",
    "            continue\n",
    "        if len(word) == 0:\n",
    "            continue\n",
    "        elif word[0].isdigit():                     ## Due to BeautifulSoup() reading LaTeX, there were many cases where\n",
    "            lowords_lst.append(word[1:])            ## the first letter of a word was a digit and followed by a normal word.\n",
    "        else:\n",
    "            lowords_lst.append(word)\n",
    "    return lowords_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def letters(url):\n",
    "      \n",
    "    '''\n",
    "    Takes in url from any website, produces 1 long string of all the letters used on that page.\n",
    "    '''\n",
    "    req = requests.get(url)\n",
    "    soup = bs4.BeautifulSoup(req.text, 'lxml')\n",
    "    raw_text = soup.get_text().replace(\"\\n\", '').replace(' ', '')\n",
    "    \n",
    "    clean_letter_upper = ''.join(filter(lambda x: re.match(\"[\\x41-\\x5A]\", x), raw_text)).lower()\n",
    "    clean_letter_lower = ''.join(filter(lambda x: re.match(\"[\\x61-\\x7A]\", x), raw_text)).lower()\n",
    "    \n",
    "    clean_letters = clean_letter_lower + clean_letter_upper\n",
    "    \n",
    "    return clean_letters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I would apply the collections.Counter() to these outputs and it will create a dictionary with key = word/letter and value = frequency. Lastly, I will transform the dictionary into a sorted dataframe with the corresponding column headings. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, for a simple website like https://books.toscrape.com/, you can see the results of the output of words() and letters(). All letters/words are made into lowercase for ease of comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>to</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>in</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>add</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>stock</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>basket</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>the</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>fiction</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>and</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>books</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Word  Frequency\n",
       "124       to         23\n",
       "52        in         22\n",
       "2        add         21\n",
       "117    stock         20\n",
       "10    basket         20\n",
       "120      the         10\n",
       "36   fiction          6\n",
       "0          a          5\n",
       "5        and          5\n",
       "17     books          3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Reading all the words off the website\n",
    "words_on_website = words(\"https://books.toscrape.com/\")\n",
    "word_counter = Counter(words_on_website)\n",
    "\n",
    "## Transforming into a dataframe\n",
    "word_dict = {}\n",
    "for key in sorted(word_counter.keys()):\n",
    "    word_dict[key] = word_counter[key]\n",
    "df_words = pd.DataFrame(list(word_dict.items()), columns = [\"Word\", \"Frequency\"]).sort_values(by = 'Frequency', \n",
    "                                                                                              ascending = False)\n",
    "# df_words.to_csv(name_of_file, index = False)\n",
    "\n",
    "\n",
    "## First ten rows\n",
    "df_words[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Letter</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>f</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>g</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>h</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>i</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>j</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Letter  Frequency\n",
       "0      a        118\n",
       "1      b         39\n",
       "2      c         66\n",
       "3      d         68\n",
       "4      e        117\n",
       "5      f         16\n",
       "6      g         22\n",
       "7      h         39\n",
       "8      i        110\n",
       "9      j          1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Reading all letters\n",
    "letters_on_website = letters(\"https://books.toscrape.com/\")\n",
    "letter_counter = Counter(letters_on_website)\n",
    "\n",
    "## Setting up as a dataframe\n",
    "letter_dict = {}\n",
    "for key in sorted(letter_counter.keys()):\n",
    "\tletter_dict[key] = letter_counter[key]\n",
    "df_letters = pd.DataFrame(list(letter_dict.items()), columns = [\"Letter\", \"Frequency\"])\n",
    "## df_letters.to_csv(name_of_file, index = False)\n",
    "\n",
    "## First ten rows\n",
    "df_letters[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last thing left to do was to apply this function to **every page of a textbook**. I found two sources of online textbooks, PreText and OpenBC, that both had identical structures for all textbooks. There was structure in the webpages, structure in the naming conventions, and structure in the url progressions from page to page. That meant that I could keep the HTML tags and for loops the same. \n",
    "\n",
    "See below for a sample of my algorithm that could read entire PreText textbooks that uses Interactive Linear Algebra (UBC Edition) by Dan Margalit, Joseph Rabinoff, and Ben Williams at https://personal.math.ubc.ca/~tbjw/ila/index.html.\n",
    "\n",
    "For example, I noticed that for every page in the textbook, the first portion of the textbook was the same, and it was just that each page had a different ending-url. Here are some examples:\n",
    "\n",
    "| Texbook Section        |                       URL                                        |\n",
    "| :-------------------:  | :--------------------------------------------------------------: |\n",
    "| Index                  | https://personal.math.ubc.ca/~tbjw/ila/index.html                |\n",
    "| 1.1 Vectors            | https://personal.math.ubc.ca/~tbjw/ila/vectors.html              |\n",
    "| 3.6 The Rank Theorem   | https://personal.math.ubc.ca/~tbjw/ila/rank-thm.html             |\n",
    "| 6.5 Complex Eigenvalues | https://personal.math.ubc.ca/~tbjw/ila/complex-eigenvalues.html |\n",
    "\n",
    "This means that **to find the URL of the next page, I only need to find the tail component of the URL**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Additional function for finding the common portion of the textbook's url pages.\n",
    "\n",
    "def common_string(string1, string2):\n",
    "    \"\"\"\n",
    "    Given two urls, provide the common url that was the base for the webpages. Must end on a / to prevent\n",
    "    redundant half-strings at the end. E.g:\n",
    "    \n",
    "    start_url = 'https://faculty.uml.edu//klevasseur/ads/index-ads.html'\n",
    "    end_url = 'https://faculty.uml.edu//klevasseur/ads/index-1.html'\n",
    "    \n",
    "    Want: 'https://faculty.uml.edu//klevasseur/ads/'\n",
    "    NOT: 'https://faculty.uml.edu//klevasseur/ads/index-'    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def slash_end(string):\n",
    "        \"\"\"\n",
    "        Recursively ensure that the last char of the string is a /\n",
    "        assume: must have a / near the the end (if not THE end)\n",
    "        \n",
    "        \"\"\"\n",
    "        if string.endswith('/'):\n",
    "            return string\n",
    "        else:\n",
    "            string = string[0:-1]\n",
    "            return slash_end(string)\n",
    "    \n",
    "    common = ''\n",
    "    for i in range(0, min(len(string1), len(string2))):\n",
    "        if string1[i] == string2[i]:\n",
    "            common += string1[i]\n",
    "        if string1[i] != string2[i]:\n",
    "            break\n",
    "    \n",
    "    result = slash_end(common)\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 51 total pages in this Linear Algebra Textbook.\n",
      "\n",
      "The first five URLs for the first five pages are:\n",
      "\n",
      "https://personal.math.ubc.ca/~tbjw/ila/index.html\n",
      "https://personal.math.ubc.ca/~tbjw/ila/colophon-1.html\n",
      "https://personal.math.ubc.ca/~tbjw/ila/preface-1.html\n",
      "https://personal.math.ubc.ca/~tbjw/ila/preface-2.html\n",
      "https://personal.math.ubc.ca/~tbjw/ila/overview.html\n"
     ]
    }
   ],
   "source": [
    "start_url = \"https://personal.math.ubc.ca/~tbjw/ila/index.html\"        # first page of the online textbook\n",
    "end_url = \"https://personal.math.ubc.ca/~tbjw/ila/colophon-2.html\"     # very last page of the online textbook\n",
    "\n",
    "## Finding all individual urls of every page in the online textbook \n",
    "lo_urls = [start_url]\n",
    "cons_url_prefix = common_string(start_url, end_url)     #in this case, this is \"https://personal.math.ubc.ca/~tbjw/ila/\"\n",
    "url = start_url\n",
    "\n",
    "while end_url not in lo_urls:                                               #loops until end_url (last page) is in the list\n",
    "    req = requests.get(url)\n",
    "    soup = bs4.BeautifulSoup(req.text, 'lxml')\n",
    "    next_url = soup.select(\".next-button.button.toolbar-item\")[0]['href']   #there is a URL stored in the \"next page\" button\n",
    "    url = cons_url_prefix + next_url\n",
    "    lo_urls.append(url)\n",
    "    \n",
    "\n",
    "print(f\"There are {len(lo_urls)} total pages in this Linear Algebra Textbook.\\n\")\n",
    "print(f\"The first five URLs for the first five pages are:\\n\")\n",
    "for url in lo_urls[:5]:\n",
    "    print(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Letter</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>30729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>6028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c</td>\n",
       "      <td>13138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d</td>\n",
       "      <td>9654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e</td>\n",
       "      <td>41817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>f</td>\n",
       "      <td>8387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>g</td>\n",
       "      <td>5093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>h</td>\n",
       "      <td>12575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>i</td>\n",
       "      <td>29647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>j</td>\n",
       "      <td>726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Letter  Frequency\n",
       "0      a      30729\n",
       "1      b       6028\n",
       "2      c      13138\n",
       "3      d       9654\n",
       "4      e      41817\n",
       "5      f       8387\n",
       "6      g       5093\n",
       "7      h      12575\n",
       "8      i      29647\n",
       "9      j        726"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Uses similar algorithm as above to read all letters from EVERY url in the textbook\n",
    "\n",
    "all_letters = ''\n",
    "for url in lo_urls:\n",
    "    all_letters += letters(url)\n",
    "letter_counter = Counter(all_letters)\n",
    "\n",
    "## Transforming into a dataframe\n",
    "letter_dict = {}\n",
    "for key in sorted(letter_counter.keys()):\n",
    "\tletter_dict[key] = letter_counter[key]\n",
    "df_letters = pd.DataFrame(list(letter_dict.items()), columns = [\"Letter\", \"Frequency\"])\n",
    "\n",
    "## first ten letters frequencies\n",
    "df_letters[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see more about this process with the exact python script for PreText Textbooks and OpenBC Textbooks in the git repository, under \"*src -> scripts*\", or at this link: https://github.com/tommysteryy/LetterAnalyzer/tree/test_branch/src/scripts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
